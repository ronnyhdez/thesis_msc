# A data driven approach to predict GPP from VIs through machine learning methods

## Introduction

The field of Earth Science has witnessed a transformative shift with the integration of Machine Learning (ML) methods, which had lead to a deeper understanding of our planet's complex ecosystems and processes [@reichstein_deep_2019]. ML methods have being used in recent years and are now well stablished in environmental sciences [@lary_machine_2016], harnessing the power of ML algorithms to explore diverse aspects of Earth's natural systems including research to understand vegetation characteristics and ecological patterns [@lehnert_retrieval_2015; @verrelst_machine_2012]

The increasing number of EC sites [@tramontana_predicting_2016] couple with the continuously growing amount of Earth system data surpassing the dozens of petabytes [@reichstein_deep_2019], has lead to an emergence of purely data-driven methodologies. These approaches have been important to further develop the quantification of global terrestrial photosynthesis [@jung_global_2011; @tramontana_predicting_2016] and have demonstrated remarkable results in the regression estimation of biogeo-physical parameters using remotely sensed reflectance data, both at local and global scales [@coops_prediction_2003; @verrelst_retrieval_2012].

Furthermore, these data-driven approaches have contributed significantly to the scientific community by providing spatial, seasonal, and interannual variations in predicted fluxes. These predictions, generated through machine learning methodologies, are now serving as important benchmarks for evaluating the performance of physical land-surface and climate models [@jung_recent_2010; @bonan_improving_2011; @anav_spatiotemporal_2015].

Some of the differences between data driven models and process-based methods are
the inherent observational character of data driven models and that functional relationships emerge from the patterns found in the data, rather than being stated before [@tramontana_predicting_2016]. So functional relationships between in-situ measured fluxes with the explanatory variables can emerge [@tramontana_predicting_2016]. This paradigm shift toward data-driven modeling to extract patterns represents an opportunity to come up with new ideas and questioning establisehd theories in earth system models.

One of the distinguishing characteristics between data-driven models and process-based methods lies in their fundamental approach. Data driven models inherently possess an observational nature where functional relationships emerge from the patterns found in the data, rather than being predefined, such as the relationships between in-situ measured fluxes and the explanatory variables. [@tramontana_predicting_2016]. This paradigm shift toward data-driven modeling to extract patterns, represents an opportunity to explore novel ideas and question established theories in earth system models [@reichstein_deep_2019].

For instance, the application of spatially explicit global data driven methods, has unveiled discrepancies in the estimation of photosynthesis within tropical rainforests when compared to climate models [@beer_terrestrial_2010]. This overestimation, has led to the creation of hypothesis for a better understanding of radiative transfer in vegetation canopies [@bonan_improving_2011] which can result in better photosynthesis estimates.

To get the most of the Earth system data there are two major challenges. The first involves efficiently extracting valuable insights from the available data. The second is developing models that learn much more from data than traditional data assimilation approaches can, while still aligning with our evolving comprehension of nature's laws [@reichstein_deep_2019].

Predicting dynamics in the biosphere is challenging given the biologically mediated processes [@reichstein_deep_2019]. "Prediction" term should not be confused with forecasting, given that most of the models are not aiming at predicting into the future, instead the focus is to predict in the past or the present times [@meyer_improving_2018]

These predictions can include many forms of uncertainty [@reichstein_deep_2019]. One is that individual ML methods can have different responses, specially when these models are applied beyond the conditions presented in the training dataset. [@jung_towards_2009; @papale_effect_2015]. A second one is that the explanatory variables used in ML methods derived from satellite remote sensing, are partial on the about the vegetation state [@tramontana_predicting_2016], and also lacks all the information to explain the complete variability in fluxes [@tramontana_uncertainty_2015]

\newpage

## Methods

```{r libraries and sources}
#| echo: false
#| message: false
#| warning: false

# Libraries
library(ggplot2)
library(cowplot)
library(lubridate)
library(purrr)
library(broom)
library(gt)
library(tidymodels)
library(broom)
library(usemodels)
library(vip)
library(h2o)

# Source files
# Source the objects created for the complete GPP trends.
# This file will source the code and load objects to memory.
source("scripts/trend_plots.R")

# Source the objects created for the complete GPP trends
source("scripts/models_data_preparation.R")

# Source file with functions to plot rf predictions
source("R/plot_exploratory.R")
```

<!--  - Sites -->
<!--  - ONEFlux for GPP -->
<!--  - Satellite imagery -->
<!--  - indices calculation -->
<!--  - Here I'm using all the bands available -->
<!--  - Cleaning satellite data -->
<!--  - Filter -->
<!--  - scaling -->
<!--  - join -->

### Eddy Covariance sites

For this study, we selected three deciduous broadleaf forest forests sites:
University of Michigan Biological Station located in northern Michigan, USA
(45°350 N 84°430 W), Bartlett experimental forest in New Hampshire, USA 
(44°06 N, 71°3 W), and the Borden Forest Research Station (44°19 N, 79°56 W) in
Ontario, Canada. 

In-situ data such as GPP was obtained utilizing the ONEFlux estimation 
processing by Ameriflux. Here, we selected GPP estimation done by the daytime
method [@pastorello2020fluxnet2015] on a daily, weekly, and monthly basis.

These sites were selected to ensure they represented a single ecosystem type,
characterized by shared environmental features. This approach allowed us to
treat the dataset as a representation of a specific vegetation type terrestrial ecosystem.

To capture seasonal variations and long-term trends, GPP data was collected over
a minimum of 2 years. Specifically, University of Michigan Biological Station 
collected data spanned from January 2015 to January 2018, Bartlett experimental
forest data ranges from January 2015 to December 2018, and Borden Forest 
Research Station from January 2015 to January 2022.

<!-- From ameriflux: -->
<!--  https://ameriflux.lbl.gov/sites/siteinfo/US-Bar -->
<!--  https://ameriflux.lbl.gov/sites/siteinfo/CA-Cbo -->
<!--  https://ameriflux.lbl.gov/sites/siteinfo/US-UMB -->

<!-- All sites are Dfb -->

<!-- The code "Dfb" in the Köppen system refers to a specific climate type, which can be described as follows: -->

<!-- "D" stands for the warm-summer continental or hemiboreal climate. -->
<!-- "f" indicates that this climate has significant precipitation in all seasons. -->
<!-- "b" indicates that the warmest month has an average temperature between 22°C and 28°C. -->

### Data Preparation

We used Google Earth Engine (GEE) to retrieve data from the Terra Moderate 
Resolution Imaging Spectroradiometer (MODIS), specifically the collection 
MOD09GA Version 6.1 product. A square polygon with an area of 3km surrounding 
the EC tower was defined for each site, and the complete data pixel values 
within this polygon was extracted for analysis.

We selected the highest quality pixels according to the `state_1km` and `qc_500m`
bit string variables. Once we had just the highest quality pixels, all the band
values were scaled by a factor of 0.0001. If any value fell outside the range
of 0 to 1 after the scaling, it was discarded.

Once all the band values were scaled, we calculate 4 Vegetation Indices: NDVI,
NIRv, EVI, and CCI. Then all the MODIS bands values and VIs were summarized in
a daily, weekly, and monthly basis to be merge with the GPP values from ONEFlux.

#### Random Forests

Regression Random forests were used as an approach to predict GPP by 
incorporating all available bands values from the MODIS dataset and the VIs. 
The primary objective was to assess the relative importance of these variables
in predicting GPP. The RF models were created using both daily and weekly 
datasets allowing for an analysis of GPP prediction across different time scales.

To implement the RF models, the `ranger` package [@wright_ranger_2017] was 
employed, utilizing 1000 trees within the forest ensemble. The models were 
trained using bootstrap resampling with 100 folds, which helps to improve the
robustness and accuracy of the predictions. 

We evaluate which variables were the most important to predict GPP...

#### AutoML

Corporis cumque voluptate cum fuga consequuntur pariatur. Excepturi perspiciatis omnis dolores dolorum officiis a consequatur. Quae distinctio quae ullam sit id. Quasi minima voluptatibus nihil ut quibusdam aut tempore nam. Repudiandae quasi quis ipsa aut. Temporibus ut rerum ea a est voluptate.

Corporis iusto necessitatibus aut rerum eum. Voluptatem repellendus soluta doloremque. Et reiciendis et animi ut enim. Fugiat consequatur hic laborum culpa blanditiis explicabo nobis quae. Quae pariatur quo et hic autem.

\newpage

## Results

### Random Forest as a better prediction model

```{r data_preparation_rf}
#| echo: false
#| message: false
#| warning: false

# 500
# Dataset to use: daily_500 for all sites
bor <- borden_daily_500 %>% 
  select(ends_with(c("_mean")),
         gpp_dt_vut_ref, total_obs) %>% 
  mutate(site = "borden")

bar <- bartlett_daily_500 %>% 
  select(ends_with(c("_mean")),
         gpp_dt_vut_ref, total_obs) %>% 
  mutate(site = "bartlett")

mich <- michigan_daily_500 %>% 
  select(ends_with(c("_mean")),
         gpp_dt_vut_ref, total_obs) %>% 
  mutate(site = "michigan")

daily_500_rf <- bind_rows(bor, bar, mich) %>% 
  select(-kndvi_mean)

# Dataset to use: weekly_500 for all sites
bor <- borden_weekly_500 %>% 
  select(ends_with(c("_mean")),
         gpp_dt_vut_ref, total_obs) %>% 
  mutate(site = "borden")

variables <- names(bor)

bar <- bartlett_weekly_500 %>% 
  mutate(site = "bartlett") %>% 
  select(all_of(variables))

mich <- michigan_weekly_500 %>% 
  mutate(site = "michigan") %>% 
  select(all_of(variables))

weekly_500_rf <- bind_rows(bor, bar, mich) %>% 
  select(-kndvi_mean)

## Dataset to use: monthly_500 for all sites
bor <- borden_monthly_500 %>% 
  select(ends_with(c("_mean")),
         gpp_dt_vut_ref, total_obs) %>% 
  mutate(site = "borden")

variables <- names(bor)

bar <- bartlett_monthly_500 %>% 
  mutate(site = "bartlett") %>% 
  select(all_of(variables))

mich <- michigan_monthly_500 %>% 
  mutate(site = "michigan") %>% 
  select(all_of(variables))

monthly_500_rf <- bind_rows(bor, bar, mich) %>% 
  select(-kndvi_mean)
```

#### Daily 500

```{r daily_500_rf}
#| echo: false
#| message: false
#| warning: false

## Make sure that the source of the file "R/plot_exploratory.R" was succesful

set.seed(123)
daily_500_split <- initial_split(daily_500_rf, strata = site)
daily_500_train <- training(daily_500_split)
daily_500_test <- testing(daily_500_split)

set.seed(234)
# daily_500_folds 
daily_500_folds <- bootstraps(daily_500_train,
                              times = 100,
                              strata = gpp_dt_vut_ref)

ranger_recipe <- 
  recipe(formula = gpp_dt_vut_ref ~ ., data = daily_500_train) %>% 
  step_select(-site, -total_obs)

ranger_spec <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_mode("regression") %>% 
  set_engine("ranger") 

ranger_workflow <- 
  workflow() %>% 
  add_recipe(ranger_recipe) %>% 
  add_model(ranger_spec) 

set.seed(3156)

# Conditional to re-run model if no artifac was saved before.
if (fs::file_exists("models/daily_500_fit_site.rds") & 
    fs::file_exists("models/daily_500_site_ranger_tune.rds")) {
  
  daily_500_fit <- readRDS("models/daily_500_fit_site.rds")
  ranger_tune <- readRDS("models/daily_500_site_ranger_tune.rds")
  
} else {  
  doParallel::registerDoParallel()
  ranger_tune <-
    tune_grid(ranger_workflow, 
              resamples = daily_500_folds, 
              grid = 12)
  
  # Final fit
  final_rf <- ranger_workflow %>% 
    finalize_workflow(select_best(ranger_tune))
  
  daily_500_fit <- last_fit(final_rf, daily_500_split)
  
  ## last_fit is saved if no model has been trained and saved.
  saveRDS(ranger_tune, "models/daily_500_site_ranger_tune.rds")
  saveRDS(daily_500_fit, "models/daily_500_fit_site.rds")
}
```


```{r predictions_plot_daily_500_rf}
#| label: fig-daily_500_rf
#| fig-cap: GPP observed and predicted values from the Random Forest model for all the sites at a daily basis. The red line represents a 1:1 relation.
#| echo: false
#| message: false
#| warning: false

# Explore RF results
## Check the metrics
metrics <- collect_metrics(daily_500_fit) 

## Collect predictions
plot_predictions_rf(daily_500_fit, metrics, 4, 4, 23.5, 22) 
```


```{r vip_plot_daily_500_rf}
#| label: fig-vip_daily_500_rf
#| fig-cap: "Variable of importance derived from the Random forest model for the daily values at 500 m spatial resolution model."
#| echo: false
#| message: false
#| warning: false

## Feature importance
imp_spec <- ranger_spec %>%
  finalize_model(select_best(ranger_tune)) %>%
  set_engine("ranger", importance = "permutation")

workflow() %>%
  add_recipe(ranger_recipe) %>%
  add_model(imp_spec) %>%
  fit(daily_500_train) %>%
  extract_fit_parsnip() %>%
  vip(aesthetics = list(alpha = 0.8, fill = "midnightblue")) +
  theme_light(base_size = 12)
```

#### Weekly 500

```{r weekly_500_rf}
#| echo: false
#| message: false
#| warning: false
set.seed(123)

weekly_500_split <- initial_split(weekly_500_rf, strata = site)
weekly_500_train <- training(weekly_500_split)
weekly_500_test <- testing(weekly_500_split)

set.seed(234)
weekly_500_folds <- bootstraps(weekly_500_train,
                              times = 100,
                              strata = gpp_dt_vut_ref)
ranger_recipe <- 
  recipe(formula = gpp_dt_vut_ref ~ ., data = weekly_500_train) %>% 
  step_select(-site, -total_obs)

ranger_spec <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_mode("regression") %>% 
  set_engine("ranger") 

ranger_workflow <- 
  workflow() %>% 
  add_recipe(ranger_recipe) %>% 
  add_model(ranger_spec) 

# Conditional to re-run model if no artifac was saved before.
if (fs::file_exists("models/weekly_500_fit_site.rds")) {
  weekly_500_fit <- readRDS("models/weekly_500_fit_site.rds")
  ranger_tune <- readRDS("models/weekly_500_site_ranger_tune.rds")
} else {
  set.seed(3156)
  
  doParallel::registerDoParallel()
  ranger_tune <-
    tune_grid(ranger_workflow, 
              resamples = weekly_500_folds, 
              grid = 12)
  
  # Final fit
  final_rf <- ranger_workflow %>% 
    finalize_workflow(select_best(ranger_tune))
  
  weekly_500_fit <- last_fit(final_rf, weekly_500_split)
  
  ## last_fit is saved if no model has been trained and saved.
  saveRDS(ranger_tune, "models/weekly_500_site_ranger_tune.rds")
  saveRDS(weekly_500_fit, "models/weekly_500_fit_site.rds")
}
```


```{r predictions_plot_weekly_500_rf}
#| label: fig-weekly_500_rf
#| fig-cap: "GPP observed and predicted values from the Random Forest for all the sites at a weekly basis. The red line represents a 1:1 relation."
#| echo: false
#| message: false
#| warning: false

# Explore RF results
## Check the metrics
metrics <- collect_metrics(weekly_500_fit) 

## Collect predictions
plot_predictions_rf(weekly_500_fit, metrics, 4, 4, 23, 25)
```


```{r vip_plot_weekly_500_rf}
#| label: fig-vip_weekly_500_rf
#| fig-cap: "Variable of importance derived from the Random forest model for the weekly values at 500 m spatial resolution model."
#| echo: false
#| message: false
#| warning: false

## Feature importance
imp_spec <- ranger_spec %>%
  finalize_model(select_best(ranger_tune)) %>%
  set_engine("ranger", importance = "permutation")

workflow() %>%
  add_recipe(ranger_recipe) %>%
  add_model(imp_spec) %>%
  fit(weekly_500_train) %>%
  extract_fit_parsnip() %>%
  vip(aesthetics = list(alpha = 0.8, fill = "midnightblue")) +
  theme_classic(base_size = 12)
```

#### Monthly

```{r}
#| echo: false
#| message: false
#| warning: false
set.seed(973)

monthly_500_split <- initial_split(monthly_500_rf, strata = site)
monthly_500_train <- training(monthly_500_split)
monthly_500_test <- testing(monthly_500_split)

set.seed(365)
# weekly_500_folds 
monthly_500_folds <- bootstraps(monthly_500_train,
                                times = 100,
                                strata = gpp_dt_vut_ref)

ranger_recipe <- 
  recipe(formula = gpp_dt_vut_ref ~ ., data = monthly_500_train) %>% 
  step_select(-site, -total_obs)

ranger_spec <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_mode("regression") %>% 
  set_engine("ranger") 

ranger_workflow <- 
  workflow() %>% 
  add_recipe(ranger_recipe) %>% 
  add_model(ranger_spec) 

# Conditional to re-run model if no artifac was saved before.
if (fs::file_exists("models/monthly_500_fit_site.rds")) {
  monthly_500_fit <- readRDS("models/monthly_500_fit_site.rds")
  ranger_tune <- readRDS("models/monthly_500_site_ranger_tune.rds")
} else {
  set.seed(3159)
  
  doParallel::registerDoParallel()
  ranger_tune <-
    tune_grid(ranger_workflow, 
              resamples = monthly_500_folds, 
              grid = 12)
  
  # Final fit
  final_rf <- ranger_workflow %>% 
    finalize_workflow(select_best(ranger_tune))
  
  monthly_500_fit <- last_fit(final_rf, monthly_500_split)
  
  ## last_fit is saved if no model has been trained and saved.
  saveRDS(ranger_tune, "models/monthly_500_site_ranger_tune.rds")
  saveRDS(monthly_500_fit, "models/monthly_500_fit_site.rds")
}
```


```{r}
#| label: fig-monthly_500_rf
#| fig-cap: "GPP observed and predicted values from the Random Forest for all the sites at a monthly basis. The red line represents a 1:1 relation."
#| echo: false
#| message: false
#| warning: false

# Explore RF results
## Check the metrics
metrics <- collect_metrics(monthly_500_fit) 

## Collect predictions
plot_predictions_rf(monthly_500_fit, metrics, 5, 5, 16, 18)
```


```{r}
#| label: fig-vip_monthly_500_rf
#| fig-cap: "Variable of importance derived from the Random forest model for the monthly values at 500 m spatial resolution model."
#| echo: false
#| message: false
#| warning: false

## Feature importance
imp_spec <- ranger_spec %>%
  finalize_model(select_best(ranger_tune)) %>%
  set_engine("ranger", importance = "permutation")

workflow() %>%
  add_recipe(ranger_recipe) %>%
  add_model(imp_spec) %>%
  fit(monthly_500_train) %>%
  extract_fit_parsnip() %>%
  vip(aesthetics = list(alpha = 0.8, fill = "midnightblue")) +
  theme_light(base_size = 12)
```

\newpage

### The potential of AutoML approaches for GPP predictions

#### Daily autoML

```{r}
#| label: fig-predictions_automl_500
#| fig-cap: "Variable of importance derived from the autoML model for the daily values at 500 m spatial resolution model."
#| echo: false
#| message: false
#| warning: false

predictions_automl <- readRDS("models/predictions_automl.rds")
perf <- readRDS("models/performance_automl.rds")

rsq <- h2o.r2(perf)
rmse <- h2o.rmse(perf)

plot_predictions_automl(predictions_automl, rmse, rsq, 3, 3, 18, 20)
```


```{r automl_importance_variable}
#| label: fig-vip_daily_500_automl
#| fig-cap: "Variable of importance derived from the autoML model for the daily values at 500 m spatial resolution model."
#| fig-width: 7
#| fig-height: 8
#| echo: false
#| message: false
#| warning: false

readRDS("models/automl_va_plot.rds") +
  theme_classic(base_size = 12) +
  scale_fill_viridis_c(direction = -1) +
  labs(title = NULL, x = "Model ID") +
  theme(axis.text.x = element_text(angle = 55, h = 1))
```

#### Weekly autoML


```{r}
#| label: fig-predictions_automl_weekly_500
#| fig-cap: "Variable of importance derived from the autoML model for the weekly values at 500 m spatial resolution model."
#| echo: false
#| message: false
#| warning: false

predictions_automl <- readRDS("models/predictions_automl_weekly.rds")
perf <- readRDS("models/performance_automl_weekly.rds")

rsq <- h2o.r2(perf)
rmse <- h2o.rmse(perf)

plot_predictions_automl(predictions_automl, rmse, rsq, 4, 4, 18, 20)
```


```{r automl_importance_variable_weekly}
#| label: fig-vip_daily_500_automl_weekly
#| fig-cap: "Variable of importance derived from the autoML model for the weekly values at 500 m spatial resolution model."
#| fig-width: 7
#| fig-height: 8
#| echo: false
#| message: false
#| warning: false

readRDS("models/automl_va_plot_weekly.rds") +
  theme_classic(base_size = 12) +
  scale_fill_viridis_c(direction = -1) +
  labs(title = NULL, x = "Model ID") +
  theme(axis.text.x = element_text(angle = 55, h = 1))
```

#### Monthly autoML

```{r}
#| label: fig-predictions_automl_monthly_500
#| fig-cap: "Variable of importance derived from the autoML model for the monthly values at 500 m spatial resolution model."
#| echo: false
#| message: false
#| warning: false
predictions_automl <- readRDS("models/predictions_automl_monthly.rds")
perf <- readRDS("models/performance_automl_monthly.rds")

rsq <- h2o.r2(perf)
rmse <- h2o.rmse(perf)

plot_predictions_automl(predictions_automl, rmse, rsq, 5, 5, 12, 13)
```

```{r automl_importance_variable_monthly}
#| label: fig-vip_monthly_500_automl_monthly
#| fig-cap: "Variable of importance derived from the autoML model for the monthly values at 500 m spatial resolution model."
#| fig-width: 7
#| fig-height: 8
#| echo: false
#| message: false
#| warning: false
readRDS("models/automl_va_plot_monthly.rds") +
  theme_classic(base_size = 12) +
  scale_fill_viridis_c(direction = -1) +
  labs(title = NULL, x = "Model ID") +
  theme(axis.text.x = element_text(angle = 55, h = 1))
```


\newpage

## Discussion


Corporis cumque voluptate cum fuga consequuntur pariatur. Excepturi perspiciatis omnis dolores dolorum officiis a consequatur. Quae distinctio quae ullam sit id. Quasi minima voluptatibus nihil ut quibusdam aut tempore nam. Repudiandae quasi quis ipsa aut. Temporibus ut rerum ea a est voluptate.

Corporis iusto necessitatibus aut rerum eum. Voluptatem repellendus soluta doloremque. Et reiciendis et animi ut enim. Fugiat consequatur hic laborum culpa blanditiis explicabo nobis quae. Quae pariatur quo et hic autem.

Sunt velit eos repellat inventore quia sunt. Et optio aut distinctio non expedita nulla sint. Explicabo sint tempore est in sunt dolores et. Modi sint earum veniam perspiciatis. Velit at beatae nam fugiat iusto.

Sed velit ipsum in qui expedita praesentium. Neque vero optio qui cumque sint. Error possimus dolor quisquam vero aut.

Autem non labore numquam. Eveniet facere id qui impedit. Sunt temporibus sit neque fugiat. Consequatur sit maiores dolorum libero provident a laudantium. Ipsum sit fugiat quis consectetur sed a provident veritatis. Consequuntur laudantium aut libero facere animi ipsum et hic.

\newpage

## References

**Just the references of this chapter, that also needs to be included in the
final references.**

::: {#refs}
:::
